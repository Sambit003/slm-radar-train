{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp0EusrMP6tV",
        "outputId": "8c9f3b87-878e-4ba6-8f58-a68200202e91"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Sambit003/slm-radar-train.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45fbU9_hjhLD",
        "outputId": "f2733086-d4d4-45d0-d36c-07cc5c0d436d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# This code shows the error in Pytorch on Nvidia Tesla T4 GPU, where T4 doesn't supports the BF16, but pytorch throws the checking as \"true\"\n",
        "\n",
        "import torch\n",
        "use_bf16 = torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
        "dtype = torch.bfloat16 if use_bf16 else torch.float32\n",
        "print(torch.cuda.is_bf16_supported())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK2ZtY3IQzpI",
        "outputId": "7522aa7f-fe46-42a4-a510-e1077cabcd02"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZIqnNft7v_-"
      },
      "outputs": [],
      "source": [
        "!pip install --ignore-installed blinker mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBv7owu5708r",
        "outputId": "33e62834-f646-4536-84b3-829c1546b12d"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQzq2AnT76IG"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/slm-radar-train/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj-TfE_pR4Ip"
      },
      "outputs": [],
      "source": [
        "# THIS IS THE INITIAL SCRIPT COMMAND\n",
        "# NOTE: DON'T RUN THIS CELL\n",
        "\n",
        "# !python slm-radar-train/train.py \\\n",
        "#     --model_name_or_path google/gemma-3-270m \\\n",
        "#     --dataset_path /content/dataset_shuffled_interleaved.jsonl \\\n",
        "#     --output_dir ./output_gemma_radar \\\n",
        "#     --hf_token \"<YOUR_HF_TOKEN>\" \\\n",
        "#     --num_train_epochs 3 \\\n",
        "#     --per_device_train_batch_size 8 \\\n",
        "#     --learning_rate 2e-4 \\\n",
        "#     --lora_r 16 \\\n",
        "#     --logging_steps 10 \\\n",
        "#     --save_strategy epoch \\\n",
        "#     --val_size 0.1 \\\n",
        "#     --test_size 0.1 \\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjZKVZEZO9eu"
      },
      "outputs": [],
      "source": [
        "!python slm-radar-train/train.py \\\n",
        "    --model_name_or_path google/gemma-3-270m \\\n",
        "    --gpu_type nvidia-t4 \\ #This argument is only needed when you're on T4 gpu\n",
        "    --dataset_path <DATASET_PATH> \\\n",
        "    --output_dir ./output_gemma_radar \\\n",
        "    --hf_token \"<YOUR_HF_TOKEN>\" \\ # HF token should be within \"\" (quotes)\n",
        "    --num_train_epochs 3 \\\n",
        "    --per_device_train_batch_size 8 \\\n",
        "    --gradient_accumulation_steps 4 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --lr_scheduler_type cosine \\\n",
        "    --warmup_ratio 0.1 \\\n",
        "    --max_grad_norm 1.0 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --label_smoothing_factor 0.1 \\\n",
        "    --lora_r 16 \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --metric_for_best_model eval_loss \\\n",
        "    --val_size 0.1 \\\n",
        "    --test_size 0.1 \\\n",
        "    --disable_gradient_checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CcoyztUFsSuE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
